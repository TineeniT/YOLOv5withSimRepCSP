{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrsaDfdVHzxt"
      },
      "source": [
        "# Custom Training with YOLOv5\n",
        "\n",
        "In this tutorial, we assemble a dataset and train a custom YOLOv5 model to recognize the objects in our dataset. To do so we will take the following steps:\n",
        "\n",
        "* Gather a dataset of images and label our dataset\n",
        "* Export our dataset to YOLOv5\n",
        "* Train YOLOv5 to recognize the objects in our dataset\n",
        "* Evaluate our YOLOv5 model's performance\n",
        "* Run test inference to view our model at work\n",
        "\n",
        "\n",
        "\n",
        "![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mvalt3hgFP5X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20013a5d-83fb-42b2-bcf7-9ae5790ec5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNveqeA1KXGy"
      },
      "source": [
        "# Step 1: Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTvDNSILZoN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600ba74d-e11e-4c40-f936-c6e764196a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/new5t\n",
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/gdrive/MyDrive/new5t/yolov5\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetup complete. Using torch 2.0.1+cu118 (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "#clone YOLOv5 and\n",
        "%cd /content/gdrive/MyDrive/new5t\n",
        "!git clone https://github.com/TineeniT/YOLOv5withSimRepCSP  # clone repo\n",
        "%cd YOLOv5withSimRepCSP\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP6USLgz2f0r"
      },
      "source": [
        "# Step 2: Assemble Our Dataset\n",
        "\n",
        "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n",
        "\n",
        "In Roboflow, you can choose between two paths:\n",
        "\n",
        "* Convert an existing dataset to YOLOv5 format. Roboflow supports over [30 formats object detection formats](https://roboflow.com/formats) for conversion.\n",
        "* Upload raw images and annotate them in Roboflow with [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "# Annotate\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)\n",
        "\n",
        "# Version\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2wGvjd4Z_92",
        "outputId": "7cd05b5f-2ac3-4e5f-edc1-d611e5f882c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/yolov5t\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/yolov5t\n",
        "from roboflow import Roboflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jjT5uIHo6l5"
      },
      "outputs": [],
      "source": [
        "# set up environment\n",
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwJcaoPGF4VI",
        "outputId": "66aacddc-b146-4ffa-dd38-53e915d3277e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/datasets/original-1 to yolov5pytorch:: 100%|██████████| 504580/504580 [00:16<00:00, 31220.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/datasets/original-1 in yolov5pytorch:: 100%|██████████| 2012/2012 [00:01<00:00, 1048.77it/s]\n"
          ]
        }
      ],
      "source": [
        "#after following the link above, recieve python code with these fields filled in\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"MrpjncFw8b5mBFtGz3li\")\n",
        "project = rf.workspace(\"project-cv5fh\").project(\"original-nqcc7\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7yAi9hd-T4B"
      },
      "source": [
        "# Step 3: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK3j2fVyxW7z",
        "outputId": "15353b9b-b520-4b63-8a2b-f5052e2d59de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/yolov5t\n",
            "2023-09-27 11:05:01.397370: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-27 11:05:02.469032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/gdrive/MyDrive/yolov5t/runs/train/T5full012/weights/best.pt, cfg=/content/gdrive/MyDrive/yolov5t/models/yolov5t9Full.yaml, data=/content/datasets/original-1/data.yaml, hyp=/content/gdrive/MyDrive/yolov5t/data/hyps/hyp.scratch-med.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=T5full0075, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "Command 'git fetch origin' timed out after 5 seconds\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"ipython\" not found, attempting AutoUpdate...\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 19.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.6)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /content/gdrive/MyDrive/yolov5t/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 v7.0-70-g589edc7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0075, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 13.8MB/s]\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1]                \n",
            "  3                -1  1     10432  models.common.RepConv                   [32, 32, 3, 1]                \n",
            "  4          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            "  5                -1  1      4224  models.common.Conv                      [64, 64, 1, 1]                \n",
            "  6                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  8                -1  1     41344  models.common.RepConv                   [64, 64, 3, 1]                \n",
            "  9          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 10                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 11                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            " 12                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 13                -1  1    164608  models.common.RepConv                   [128, 128, 3, 1]              \n",
            " 14          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 16                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            " 17                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 18                -1  1    656896  models.common.RepConv                   [256, 256, 3, 1]              \n",
            " 19          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 21                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 22                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 23                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 24          [-1, 11]  1         0  models.common.Concat                    [1]                           \n",
            " 25                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 26                -1  1    164608  models.common.RepConv                   [128, 128, 3, 1]              \n",
            " 27                -1  1     33280  models.common.Conv                      [128, 256, 1, 1]              \n",
            " 28                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 29                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 30           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 31                -1  1     16512  models.common.Conv                      [256, 64, 1, 1]               \n",
            " 32                -1  1     41344  models.common.RepConv                   [64, 64, 3, 1]                \n",
            " 33                -1  1      8448  models.common.Conv                      [64, 128, 1, 1]               \n",
            " 34                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 35          [-1, 28]  1         0  models.common.Concat                    [1]                           \n",
            " 36                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 37                -1  1    164608  models.common.RepConv                   [128, 128, 3, 1]              \n",
            " 38                -1  1     33280  models.common.Conv                      [128, 256, 1, 1]              \n",
            " 39                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 40          [-1, 22]  1         0  models.common.Concat                    [1]                           \n",
            " 41                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 42                -1  1    656896  models.common.RepConv                   [256, 256, 3, 1]              \n",
            " 43                -1  1    132096  models.common.Conv                      [256, 512, 1, 1]              \n",
            " 44      [33, 38, 43]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5t9Full summary: 173 layers, 6030463 parameters, 6030463 gradients, 12.9 GFLOPs\n",
            "\n",
            "Transferred 304/305 items from /content/gdrive/MyDrive/yolov5t/runs/train/T5full012/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0075) with parameter groups 51 weight(decay=0.0), 46 weight(decay=0.0005), 54 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/original-1/train/labels... 700 images, 0 backgrounds, 0 corrupt: 100% 700/700 [00:00<00:00, 728.59it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/original-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/original-1/valid/labels... 150 images, 0 backgrounds, 0 corrupt: 100% 150/150 [00:00<00:00, 434.86it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/original-1/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.74 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/T5full0075/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/T5full0075\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/49       2.9G    0.01104   0.005789   0.006978         28        640: 100% 44/44 [03:21<00:00,  4.58s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:08<00:00,  1.67s/it]\n",
            "                   all        150        150      0.904       0.92      0.961      0.915\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/49      3.71G     0.0119    0.00612   0.006949         38        640: 100% 44/44 [03:20<00:00,  4.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.85it/s]\n",
            "                   all        150        150       0.89       0.92      0.965      0.874\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/49      3.71G    0.01101   0.005719   0.007287         37        640: 100% 44/44 [03:30<00:00,  4.79s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.10it/s]\n",
            "                   all        150        150      0.747      0.953      0.941      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/49      3.71G    0.01255   0.006147   0.006925         35        640: 100% 44/44 [03:20<00:00,  4.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.74it/s]\n",
            "                   all        150        150      0.896      0.907      0.953      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/49      3.71G    0.01256   0.006054   0.007327         31        640: 100% 44/44 [03:29<00:00,  4.75s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.75it/s]\n",
            "                   all        150        150      0.836      0.907      0.948      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/49      3.71G    0.01181   0.005967    0.00727         46        640: 100% 44/44 [03:26<00:00,  4.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.67it/s]\n",
            "                   all        150        150      0.897      0.916      0.962      0.889\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/49      3.71G    0.01208   0.006034   0.006889         45        640: 100% 44/44 [03:13<00:00,  4.40s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.56it/s]\n",
            "                   all        150        150      0.905      0.903      0.944      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/49      3.71G    0.01207   0.006038   0.006871         32        640: 100% 44/44 [03:25<00:00,  4.67s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.92it/s]\n",
            "                   all        150        150      0.883       0.92      0.955      0.903\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/49      3.71G    0.01298   0.006008   0.007293         37        640: 100% 44/44 [03:28<00:00,  4.74s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.80it/s]\n",
            "                   all        150        150      0.885      0.874       0.95      0.879\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/49      3.71G    0.01241   0.006233   0.006642         25        640: 100% 44/44 [03:22<00:00,  4.60s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.79it/s]\n",
            "                   all        150        150      0.882       0.93      0.957      0.874\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/49      3.71G    0.01151   0.006024   0.006849         33        640: 100% 44/44 [03:30<00:00,  4.80s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.79it/s]\n",
            "                   all        150        150       0.83      0.937      0.962      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/49      3.71G    0.01189   0.005848   0.006893         34        640: 100% 44/44 [03:28<00:00,  4.73s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.78it/s]\n",
            "                   all        150        150      0.898      0.898      0.965      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/49      3.71G    0.01186   0.005728    0.00641         37        640: 100% 44/44 [03:27<00:00,  4.71s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.94it/s]\n",
            "                   all        150        150      0.888      0.913       0.95      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/49      3.71G    0.01159   0.005943   0.006668         27        640: 100% 44/44 [03:24<00:00,  4.64s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.85it/s]\n",
            "                   all        150        150       0.79      0.967      0.953      0.878\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/49      3.71G    0.01211   0.006302   0.006708         43        640: 100% 44/44 [03:36<00:00,  4.91s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.03it/s]\n",
            "                   all        150        150      0.885      0.911       0.96      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/49      3.71G    0.01208   0.006142   0.006571         47        640: 100% 44/44 [03:29<00:00,  4.77s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.80it/s]\n",
            "                   all        150        150      0.787      0.867      0.905      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/49      3.71G    0.01208   0.005895   0.006687         29        640: 100% 44/44 [03:23<00:00,  4.63s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.15it/s]\n",
            "                   all        150        150      0.862      0.873      0.952      0.905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/49      3.71G    0.01164   0.006239   0.006768         29        640: 100% 44/44 [03:26<00:00,  4.68s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.13it/s]\n",
            "                   all        150        150      0.867      0.927      0.962      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/49      3.71G    0.01182   0.006036   0.007177         37        640: 100% 44/44 [03:23<00:00,  4.62s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.35it/s]\n",
            "                   all        150        150      0.727       0.92      0.932      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/49      3.71G    0.01146   0.005674   0.007603         40        640: 100% 44/44 [03:27<00:00,  4.72s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.12it/s]\n",
            "                   all        150        150      0.857       0.89      0.937      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/49      3.71G    0.01155   0.005656   0.006481         38        640: 100% 44/44 [03:31<00:00,  4.81s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.76it/s]\n",
            "                   all        150        150      0.861      0.943      0.962      0.907\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/49      3.71G     0.0114   0.005627   0.006431         31        640: 100% 44/44 [03:35<00:00,  4.91s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:05<00:00,  1.01s/it]\n",
            "                   all        150        150      0.853      0.963      0.965      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/49      3.71G    0.01151    0.00589   0.006622         38        640: 100% 44/44 [03:37<00:00,  4.94s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.76it/s]\n",
            "                   all        150        150      0.883        0.9      0.963      0.911\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/49      3.71G    0.01124   0.005544   0.006853         32        640: 100% 44/44 [03:26<00:00,  4.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.74it/s]\n",
            "                   all        150        150      0.875      0.924      0.962      0.918\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/49      3.71G    0.01183   0.005809   0.006887         36        640: 100% 44/44 [03:31<00:00,  4.81s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.03it/s]\n",
            "                   all        150        150      0.895      0.919      0.954      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/49      3.71G    0.01119   0.005889   0.007104         33        640: 100% 44/44 [03:34<00:00,  4.87s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.99it/s]\n",
            "                   all        150        150      0.922      0.917      0.963      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/49      3.71G     0.0118   0.005736   0.007282         35        640: 100% 44/44 [03:27<00:00,  4.71s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.82it/s]\n",
            "                   all        150        150      0.901      0.898      0.957      0.898\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/49      3.71G    0.01069    0.00582   0.006853         32        640: 100% 44/44 [03:34<00:00,  4.88s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.70it/s]\n",
            "                   all        150        150      0.892      0.917      0.964      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/49      3.71G    0.01076   0.005969   0.006455         38        640: 100% 44/44 [03:31<00:00,  4.81s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.28it/s]\n",
            "                   all        150        150       0.88      0.936       0.96      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/49      3.71G    0.01084   0.005781   0.005902         43        640: 100% 44/44 [03:32<00:00,  4.82s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.85it/s]\n",
            "                   all        150        150       0.88      0.952      0.964      0.901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/49      3.71G    0.01043   0.005773   0.006097         34        640: 100% 44/44 [03:32<00:00,  4.82s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.06it/s]\n",
            "                   all        150        150      0.907      0.937      0.965      0.912\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/49      3.71G    0.01001   0.005445   0.006375         22        640: 100% 44/44 [03:16<00:00,  4.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.83it/s]\n",
            "                   all        150        150      0.834      0.968      0.969      0.928\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/49      3.71G    0.01068   0.005471   0.006823         43        640: 100% 44/44 [03:21<00:00,  4.58s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.05it/s]\n",
            "                   all        150        150      0.888      0.933      0.963      0.919\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/49      3.71G    0.01136   0.005646   0.006538         25        640: 100% 44/44 [03:26<00:00,  4.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.12it/s]\n",
            "                   all        150        150      0.904      0.943      0.963      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/49      3.71G    0.01119      0.006   0.006494         29        640: 100% 44/44 [03:37<00:00,  4.93s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.75it/s]\n",
            "                   all        150        150      0.906      0.942      0.968      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/49      3.71G    0.01074    0.00531   0.006579         26        640: 100% 44/44 [03:37<00:00,  4.95s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.82it/s]\n",
            "                   all        150        150       0.89      0.957      0.969      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/49      3.71G    0.01101   0.005784    0.00694         31        640: 100% 44/44 [03:30<00:00,  4.79s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.88it/s]\n",
            "                   all        150        150       0.76      0.953      0.952      0.905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/49      3.71G    0.01129   0.006058   0.007308         45        640: 100% 44/44 [03:27<00:00,  4.72s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.72it/s]\n",
            "                   all        150        150      0.779      0.887      0.937      0.888\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/49      3.71G       0.01   0.005663   0.006397         35        640: 100% 44/44 [03:24<00:00,  4.66s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.93it/s]\n",
            "                   all        150        150      0.886      0.932      0.965      0.908\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/49      3.71G    0.01106   0.005563   0.006324         38        640: 100% 44/44 [03:24<00:00,  4.66s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.84it/s]\n",
            "                   all        150        150      0.905       0.96      0.973      0.933\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/49      3.71G    0.01043   0.005729   0.006621         36        640: 100% 44/44 [03:28<00:00,  4.74s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.85it/s]\n",
            "                   all        150        150      0.897       0.94      0.963      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/49      3.71G    0.01115   0.005751    0.00662         38        640: 100% 44/44 [03:30<00:00,  4.79s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.74it/s]\n",
            "                   all        150        150      0.864      0.927      0.963      0.917\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/49      3.71G    0.01113   0.005716    0.00781         28        640: 100% 44/44 [03:26<00:00,  4.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.09it/s]\n",
            "                   all        150        150      0.923       0.92      0.969      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/49      3.71G    0.01126   0.005729   0.006887         31        640: 100% 44/44 [03:27<00:00,  4.71s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.25it/s]\n",
            "                   all        150        150       0.93      0.926      0.967      0.924\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/49      3.71G    0.01108   0.005345   0.007099         46        640: 100% 44/44 [03:18<00:00,  4.50s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.86it/s]\n",
            "                   all        150        150      0.838      0.933      0.963      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/49      3.71G    0.01044   0.005437    0.00672         38        640: 100% 44/44 [03:31<00:00,  4.80s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.04it/s]\n",
            "                   all        150        150      0.921      0.927      0.966      0.925\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/49      3.71G    0.01051    0.00554   0.006546         42        640: 100% 44/44 [03:25<00:00,  4.66s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.02it/s]\n",
            "                   all        150        150       0.89      0.933      0.965      0.927\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/49      3.71G    0.01091   0.005658     0.0065         38        640: 100% 44/44 [03:28<00:00,  4.74s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.47it/s]\n",
            "                   all        150        150      0.879      0.892      0.966      0.933\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/49      3.71G    0.01113   0.005662    0.00689         30        640: 100% 44/44 [03:26<00:00,  4.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:03<00:00,  1.58it/s]\n",
            "                   all        150        150      0.882       0.92      0.968      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/49      3.71G    0.01101   0.005941   0.007711         39        640: 100% 44/44 [03:31<00:00,  4.80s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.77it/s]\n",
            "                   all        150        150      0.922      0.927      0.969      0.933\n",
            "\n",
            "50 epochs completed in 2.954 hours.\n",
            "Optimizer stripped from runs/train/T5full0075/weights/last.pt, 12.3MB\n",
            "Optimizer stripped from runs/train/T5full0075/weights/best.pt, 12.3MB\n",
            "\n",
            "Validating runs/train/T5full0075/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5t9Full summary: 146 layers, 6024767 parameters, 0 gradients, 12.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:25<00:00,  5.06s/it]\n",
            "                   all        150        150      0.905       0.96      0.973      0.932\n",
            "               accepts        150         75      0.884      0.973      0.974      0.941\n",
            "               rejects        150         75      0.927      0.947      0.972      0.923\n",
            "Results saved to \u001b[1mruns/train/T5full0075\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/YOLOv5withSimRepCSP\n",
        "!python train.py --data /content/datasets/original-1/data.yaml --epochs 50 --name '' --weights '' --cfg /content/gdrive/MyDrive/YOLOv5withSimRepCSP/models/yolov5_SimRepCSP.yaml  --batch-size 16 --hyp /content/gdrive/MyDrive/yolov5t/data/hyps/hyp.scratch-med.yaml --img 640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0969e7d2-ac75-4d39-b37e-5599a822f5dd",
        "id": "BXBlhweFhp87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/yolov5t\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/datasets/original-1/data.yaml, weights=['/content/gdrive/MyDrive/yolov5t/runs/train/T5full0075/weights/best.pt'], batch_size=16, imgsz=640, conf_thres=0.5, iou_thres=0.5, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=ft9v5, exist_ok=False, half=False, dnn=False\n",
            "WARNING ⚠️ confidence threshold 0.5 > 0.001 produces invalid results\n",
            "YOLOv5 🚀 v7.0-70-g589edc7 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5t9Full summary: 146 layers, 6024767 parameters, 0 gradients, 12.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/original-1/test/labels.cache... 150 images, 0 backgrounds, 0 corrupt: 100% 150/150 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:16<00:00,  1.63s/it]\n",
            "                   all        150        150      0.912      0.893      0.922        0.9\n",
            "               accepts        150         75      0.899       0.92      0.952      0.945\n",
            "               rejects        150         75      0.924      0.867      0.891      0.855\n",
            "Speed: 0.2ms pre-process, 9.1ms inference, 4.1ms NMS per image at shape (16, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/val/ft9v52\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/yolov5t\n",
        "!python val.py --data /content/datasets/original-1/data.yaml  --img 640 --batch 16 --conf 0.5 --iou 0.5  --name ft9v5 --weights '/content/gdrive/MyDrive/yolov5t/runs/train/T5full0075/weights/best.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtmS7_TXFsT3"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWjjiBcic3Vz",
        "outputId": "85e3b841-898d-4a2f-cc2f-4ceff9b707fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/yolov5t/runs/best_5t9001.pt'], source=/content/datasets/original-1/test/images, data=/content/datasets/original-1/data.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-70-g589edc7 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5t9 summary: 186 layers, 34025663 parameters, 0 gradients, 70.4 GFLOPs\n",
            "image 1/150 /content/datasets/original-1/test/images/AN_101_jpg.rf.e2d03e5f4d836dce6c65bbc57ba8daa2.jpg: 640x384 1 accepts, 53.6ms\n",
            "image 2/150 /content/datasets/original-1/test/images/AN_107_jpg.rf.2aaa6de950c650805ea6da5eb80acff6.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 3/150 /content/datasets/original-1/test/images/AN_133_jpg.rf.9f2bf4684392e4c6e75fb7879c4fff19.jpg: 640x384 1 accepts, 22.2ms\n",
            "image 4/150 /content/datasets/original-1/test/images/AN_141_jpg.rf.e05407f145056db995d927179cb11a4f.jpg: 640x384 1 accepts, 22.2ms\n",
            "image 5/150 /content/datasets/original-1/test/images/AN_153_jpg.rf.6f2890a074457a8decd9b59126c7ce40.jpg: 384x640 1 accepts, 58.0ms\n",
            "image 6/150 /content/datasets/original-1/test/images/AN_158_jpg.rf.79f41a9ccc95f267b5d3c0a2990d886f.jpg: 384x640 1 accepts, 22.6ms\n",
            "image 7/150 /content/datasets/original-1/test/images/AN_162_jpg.rf.faaa1b217e4430a7aea76a4d3eaef378.jpg: 640x384 1 accepts, 22.4ms\n",
            "image 8/150 /content/datasets/original-1/test/images/AN_170_jpg.rf.0b28952abb1eb223ff01ad4e827cf13f.jpg: 384x640 1 accepts, 22.6ms\n",
            "image 9/150 /content/datasets/original-1/test/images/AN_172_jpg.rf.eeaf2804f31460adc7d48f2cb8f431c4.jpg: 384x640 1 accepts, 22.6ms\n",
            "image 10/150 /content/datasets/original-1/test/images/AN_177_jpg.rf.08c021e17e73e03aaf978e3ab85bd419.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 11/150 /content/datasets/original-1/test/images/AN_182_jpg.rf.4d990ce8798545be4ef3c3762ad0bf64.jpg: 640x384 1 accepts, 22.2ms\n",
            "image 12/150 /content/datasets/original-1/test/images/AN_184_jpg.rf.238452ab806209705bc87cdc45fb63d1.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 13/150 /content/datasets/original-1/test/images/AN_188_jpg.rf.1451ff8c30cbf9826d6cdfb390e05227.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 14/150 /content/datasets/original-1/test/images/AN_190_jpg.rf.60e76d87a24ebcf7340e25e284800f20.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 15/150 /content/datasets/original-1/test/images/AN_209_jpg.rf.c26bc35061f4a4addb226bf09c42e0bc.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 16/150 /content/datasets/original-1/test/images/AN_215_jpg.rf.38b425fd834b0d8d8ed4db836be0daae.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 17/150 /content/datasets/original-1/test/images/AN_216_jpg.rf.add611b708de0b043820a3f9d3d0411b.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 18/150 /content/datasets/original-1/test/images/AN_220_jpg.rf.cea761dc935c45d6ee020d6a6147eec1.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 19/150 /content/datasets/original-1/test/images/AN_221_jpg.rf.cf01268cb022b190dfe2f1d532047ff6.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 20/150 /content/datasets/original-1/test/images/AN_223_jpg.rf.9f61426a861265188d367c3616107d61.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 21/150 /content/datasets/original-1/test/images/AN_233_jpg.rf.2ec351e8f0ce1e761c95623943c8ead5.jpg: 640x384 1 accepts, 22.4ms\n",
            "image 22/150 /content/datasets/original-1/test/images/AN_238_jpg.rf.61e5c20cf1695b6d1488dddc8dd27bee.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 23/150 /content/datasets/original-1/test/images/AN_240_jpg.rf.cf08b98e8a204c80accad9e6a08b5471.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 24/150 /content/datasets/original-1/test/images/AN_244_jpg.rf.46f8d6b4615654d3fa69334a56096b7c.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 25/150 /content/datasets/original-1/test/images/AN_248_jpg.rf.5ff95a989b0a1b2c3222d1f8b7165941.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 26/150 /content/datasets/original-1/test/images/AN_254_jpg.rf.95901c25467515493c2028d37ae4d076.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 27/150 /content/datasets/original-1/test/images/AN_259_jpg.rf.118748c7f225482e2c83232d2f5c1203.jpg: 384x640 1 accepts, 22.6ms\n",
            "image 28/150 /content/datasets/original-1/test/images/AN_267_jpg.rf.9c9f6578ed2c0574e642e0e10a3d509f.jpg: 640x384 1 accepts, 22.4ms\n",
            "image 29/150 /content/datasets/original-1/test/images/AN_268_jpg.rf.09b5343f0d331cdccd0cbb01f08c3266.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 30/150 /content/datasets/original-1/test/images/AN_272_jpg.rf.cdd63fa9c0ab4462a77a973d68f45063.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 31/150 /content/datasets/original-1/test/images/AN_281_jpg.rf.38070265d1417924a43a74a58e857155.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 32/150 /content/datasets/original-1/test/images/AN_288_jpg.rf.ce129a9aed3f2390b40c896bea99c84d.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 33/150 /content/datasets/original-1/test/images/AN_289_jpg.rf.2a8a69efc554acd520a0459165a928e5.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 34/150 /content/datasets/original-1/test/images/AN_292_jpg.rf.f6b96718eb7c8f6aed40e51909471082.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 35/150 /content/datasets/original-1/test/images/AN_293_jpg.rf.2fbb807e29884646595c4a881c9f6350.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 36/150 /content/datasets/original-1/test/images/AN_300_jpg.rf.e9c816aebd040b79045365e0e029cd13.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 37/150 /content/datasets/original-1/test/images/AN_307_jpg.rf.d829047db462e025eb28bd9b8305e445.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 38/150 /content/datasets/original-1/test/images/AN_326_jpg.rf.b106f2685f7d1b03690e67cb466e528a.jpg: 640x384 1 accepts, 1 rejects, 22.4ms\n",
            "image 39/150 /content/datasets/original-1/test/images/AN_328_jpg.rf.2ddd194cc5560f4136acd0fa6418aa12.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 40/150 /content/datasets/original-1/test/images/AN_330_jpg.rf.ae9a75ff902ee8db2cf100ce206c4688.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 41/150 /content/datasets/original-1/test/images/AN_334_jpg.rf.ea9d3e7fcef13e3195788bd16d930ea3.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 42/150 /content/datasets/original-1/test/images/AN_33_jpg.rf.060b484588691cf9559d9d4093ea282f.jpg: 640x384 1 accepts, 23.4ms\n",
            "image 43/150 /content/datasets/original-1/test/images/AN_340_jpg.rf.50329062aa1133bac8f70c20e348bb66.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 44/150 /content/datasets/original-1/test/images/AN_343_jpg.rf.861b4e012865eb79a85cc1bbbd56eaf3.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 45/150 /content/datasets/original-1/test/images/AN_344_jpg.rf.953bb7981c233fefad6e3aab9e3dabe5.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 46/150 /content/datasets/original-1/test/images/AN_347_jpg.rf.5fda0e6dda2316d5cb756e49215625cb.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 47/150 /content/datasets/original-1/test/images/AN_360_jpg.rf.8658bb569cb891c4ac13583a14abc5ec.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 48/150 /content/datasets/original-1/test/images/AN_361_jpg.rf.1e25edad7a77e2d8fcdb930d0a58f9e6.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 49/150 /content/datasets/original-1/test/images/AN_366_jpg.rf.e53728ef8d0e58aad471449987feb68f.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 50/150 /content/datasets/original-1/test/images/AN_369_jpg.rf.be819001ff337647aa138fd25df81c11.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 51/150 /content/datasets/original-1/test/images/AN_36_jpg.rf.249aa3ea9f7ac6a0281f36608c9d220d.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 52/150 /content/datasets/original-1/test/images/AN_376_jpg.rf.fd148d3a0bbdbe1be751504debc797ab.jpg: 640x384 1 accepts, 22.8ms\n",
            "image 53/150 /content/datasets/original-1/test/images/AN_379_jpg.rf.65d05d0db0ca4916246d92efc92c19d6.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 54/150 /content/datasets/original-1/test/images/AN_380_jpg.rf.712130b5c35be93b7b15be9e1f118719.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 55/150 /content/datasets/original-1/test/images/AN_383_jpg.rf.52ec18e7ca486964c88bfded6ecd5216.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 56/150 /content/datasets/original-1/test/images/AN_400_jpg.rf.cff6bde6b77ac72ffe49fb8de99a4e09.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 57/150 /content/datasets/original-1/test/images/AN_401_jpg.rf.f356db717277035d502a76c97e563968.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 58/150 /content/datasets/original-1/test/images/AN_408_jpg.rf.43027ad7d64d7e54513a7f83f17c6aa7.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 59/150 /content/datasets/original-1/test/images/AN_410_jpg.rf.a0ea0dc89e856c4d84f69bb462ffa8ff.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 60/150 /content/datasets/original-1/test/images/AN_42_jpg.rf.2c54929d06f187d049c7907503776ce6.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 61/150 /content/datasets/original-1/test/images/AN_437_jpg.rf.b613d6e806f1eac782f9da9aa7be9b6e.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 62/150 /content/datasets/original-1/test/images/AN_438_jpg.rf.1a4b0037384b739532646751206f3e76.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 63/150 /content/datasets/original-1/test/images/AN_439_jpg.rf.e9f37a3e8094770082c5e30026609671.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 64/150 /content/datasets/original-1/test/images/AN_447_jpg.rf.775c42b9d574c2fb624d6941dd36ba7c.jpg: 640x480 1 rejects, 47.5ms\n",
            "image 65/150 /content/datasets/original-1/test/images/AN_450_jpg.rf.c249df720db965f32d93aa42b0ef0806.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 66/150 /content/datasets/original-1/test/images/AN_456_jpg.rf.a6ece62732dbcd72febc5f661e9214ca.jpg: 640x480 1 accepts, 1 rejects, 26.7ms\n",
            "image 67/150 /content/datasets/original-1/test/images/AN_458_jpg.rf.d7db16c2a708b4b5aeff4b94e15cccec.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 68/150 /content/datasets/original-1/test/images/AN_462_jpg.rf.a6702f44a162c1f5a43b05e55270f128.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 69/150 /content/datasets/original-1/test/images/AN_476_jpg.rf.4ad11aeef3f8c6c08bd7fc0081f94f4f.jpg: 640x352 1 accepts, 48.9ms\n",
            "image 70/150 /content/datasets/original-1/test/images/AN_482_jpg.rf.920f31c30711a2e879bd266a2c5aebca.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 71/150 /content/datasets/original-1/test/images/AN_52_jpg.rf.101c68d7d8fc017a54823d775ba23b20.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 72/150 /content/datasets/original-1/test/images/AN_71_jpg.rf.5119e0ee6b94bc02e742f251a88ce0a0.jpg: 640x384 1 accepts, 22.2ms\n",
            "image 73/150 /content/datasets/original-1/test/images/AN_75_jpg.rf.767b2465670d94ae6dceabfa58333ce9.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 74/150 /content/datasets/original-1/test/images/AN_76_jpg.rf.e3d8c41b7fa905bb43ce9a28c81f3be4.jpg: 640x384 1 accepts, 22.2ms\n",
            "image 75/150 /content/datasets/original-1/test/images/AN_92_jpg.rf.a1aaaa444930b29c06e912ed441be429.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 76/150 /content/datasets/original-1/test/images/Re_105_jpg.rf.282ea3a26a2a23fb314c7633e6e203cc.jpg: 640x384 1 accepts, 22.2ms\n",
            "image 77/150 /content/datasets/original-1/test/images/Re_108_jpg.rf.a35342cc53b6070ced63410e5f26751d.jpg: 640x384 1 rejects, 22.3ms\n",
            "image 78/150 /content/datasets/original-1/test/images/Re_111_jpg.rf.72292ed53b25cda310ac9c38f43d4e18.jpg: 640x384 1 rejects, 21.4ms\n",
            "image 79/150 /content/datasets/original-1/test/images/Re_114_jpg.rf.e0d2d9fee1e08ae2126c187bfaadd940.jpg: 640x384 1 rejects, 21.4ms\n",
            "image 80/150 /content/datasets/original-1/test/images/Re_116_jpg.rf.8100af8cbcbaa3a4d89a0d4f7a53a996.jpg: 640x384 1 accepts, 21.4ms\n",
            "image 81/150 /content/datasets/original-1/test/images/Re_122_jpg.rf.15ec93d283938119a3643a253a81b502.jpg: 640x384 1 rejects, 21.4ms\n",
            "image 82/150 /content/datasets/original-1/test/images/Re_12_jpg.rf.5914a3d0b026ffc4cd5a83bb6696cd1f.jpg: 640x384 1 accepts, 20.9ms\n",
            "image 83/150 /content/datasets/original-1/test/images/Re_138_jpg.rf.4250fbe5dfde50dbf120c77e5d60a3ec.jpg: 640x384 1 rejects, 20.9ms\n",
            "image 84/150 /content/datasets/original-1/test/images/Re_139_jpg.rf.93ca399fbfe8f9f1a8572462caa8b455.jpg: 640x384 1 rejects, 20.9ms\n",
            "image 85/150 /content/datasets/original-1/test/images/Re_149_jpg.rf.0ed55ff1d7c0169a0c0261d02dca00fa.jpg: 640x384 1 rejects, 20.9ms\n",
            "image 86/150 /content/datasets/original-1/test/images/Re_154_jpg.rf.554e05a89d56bc8d1ba7803b16d02e43.jpg: 640x384 1 rejects, 20.9ms\n",
            "image 87/150 /content/datasets/original-1/test/images/Re_156_jpg.rf.dbd164cc835590c5dc7ad87cd0122638.jpg: 640x384 1 rejects, 20.9ms\n",
            "image 88/150 /content/datasets/original-1/test/images/Re_159_jpg.rf.dec24ce2419834f41aa59b6f282d1b3c.jpg: 640x480 1 rejects, 25.1ms\n",
            "image 89/150 /content/datasets/original-1/test/images/Re_162_jpg.rf.007753e4f78e90a6a18b6384d0238a41.jpg: 640x480 1 rejects, 25.1ms\n",
            "image 90/150 /content/datasets/original-1/test/images/Re_164_jpg.rf.eacd323553025bf7cfddd51742422b72.jpg: 640x480 1 rejects, 25.1ms\n",
            "image 91/150 /content/datasets/original-1/test/images/Re_180_jpg.rf.f1ee488c864380f0144116db83fa507a.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 92/150 /content/datasets/original-1/test/images/Re_182_jpg.rf.17c0d30ed55ccc7311b29f3db6e3dfd4.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 93/150 /content/datasets/original-1/test/images/Re_187_jpg.rf.44229e365ed06b3af81155fc3a3e0d6f.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 94/150 /content/datasets/original-1/test/images/Re_192_jpg.rf.a087cc3456712d7f1e8cfc5f8452b45f.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 95/150 /content/datasets/original-1/test/images/Re_198_jpg.rf.da9e4bbe2e7464a13046b05b7527e5b9.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 96/150 /content/datasets/original-1/test/images/Re_203_jpg.rf.0a02e8f77f93589c34334c6672222e60.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 97/150 /content/datasets/original-1/test/images/Re_204_jpg.rf.b94fa2f928aea6a8d244cfe21729a33b.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 98/150 /content/datasets/original-1/test/images/Re_208_jpg.rf.80c3309c442cabba022a8777fedecc0d.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 99/150 /content/datasets/original-1/test/images/Re_209_jpg.rf.08ae4b15d5f6a11811b754fa70c62cba.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 100/150 /content/datasets/original-1/test/images/Re_229_jpg.rf.b0181e9c2cb63ffa4bf27478949ec3a2.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 101/150 /content/datasets/original-1/test/images/Re_22_jpg.rf.1e36a02dc875b512b7575c58eed7283d.jpg: 640x384 1 accepts, 22.4ms\n",
            "image 102/150 /content/datasets/original-1/test/images/Re_235_jpg.rf.0903e455223e7b42db7fb22d4a51cc7f.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 103/150 /content/datasets/original-1/test/images/Re_239_jpg.rf.f11cbd76d818bbdb2d839a74713f695f.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 104/150 /content/datasets/original-1/test/images/Re_23_jpg.rf.c298c23ea58ba5e160bd639eeddeac5d.jpg: 640x384 1 rejects, 22.5ms\n",
            "image 105/150 /content/datasets/original-1/test/images/Re_240_jpg.rf.2d4712ec47de2dcf7c397d0a134b432f.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 106/150 /content/datasets/original-1/test/images/Re_242_jpg.rf.0e71de1fffce85191ac54c4ee9cda497.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 107/150 /content/datasets/original-1/test/images/Re_243_jpg.rf.879610e6502229c61c4df080618da59b.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 108/150 /content/datasets/original-1/test/images/Re_250_jpg.rf.8f7cf106706d07cf2bc9ee49b6bbaee7.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 109/150 /content/datasets/original-1/test/images/Re_272_jpg.rf.a45a5420d0b793cc21c929751c270564.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 110/150 /content/datasets/original-1/test/images/Re_280_jpg.rf.4918dca7ddccf960881970960112b27c.jpg: 640x480 1 rejects, 34.2ms\n",
            "image 111/150 /content/datasets/original-1/test/images/Re_281_jpg.rf.4e5b330c1e3f03372673476b2ffbc5f2.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 112/150 /content/datasets/original-1/test/images/Re_28_jpg.rf.49eb221cdce20b95870f8d1684b59788.jpg: 640x384 1 rejects, 22.4ms\n",
            "image 113/150 /content/datasets/original-1/test/images/Re_295_jpg.rf.53da8945d28284f3cf5a7da4953fa663.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 114/150 /content/datasets/original-1/test/images/Re_300_jpg.rf.af0e37c7f4b4b1b9341a0731e2e2015d.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 115/150 /content/datasets/original-1/test/images/Re_301_jpg.rf.7cfd2faa75389ed2f353e6a02d47f88c.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 116/150 /content/datasets/original-1/test/images/Re_306_jpg.rf.83f50c6459386453f238652313c09dbb.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 117/150 /content/datasets/original-1/test/images/Re_31_jpg.rf.8dcf6a0ba5146836f8d50fda9f3b7338.jpg: 640x384 1 accepts, 22.3ms\n",
            "image 118/150 /content/datasets/original-1/test/images/Re_321_jpg.rf.f97dad8c7ded3dbd1c833083891145d5.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 119/150 /content/datasets/original-1/test/images/Re_325_jpg.rf.5f7cdec798a4b902a48da027f2c90d33.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 120/150 /content/datasets/original-1/test/images/Re_332_jpg.rf.4974cb80a5ed08f1ed7db42534e7747b.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 121/150 /content/datasets/original-1/test/images/Re_334_jpg.rf.95e0f9a49a9769c091b0f20142187e82.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 122/150 /content/datasets/original-1/test/images/Re_341_jpg.rf.a907e61c594e269a277054bbc9ac418d.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 123/150 /content/datasets/original-1/test/images/Re_34_jpg.rf.7b42fb419069ec549175c856e834b0ab.jpg: 640x384 1 accepts, 22.4ms\n",
            "image 124/150 /content/datasets/original-1/test/images/Re_364_jpg.rf.6eee75893fded1b34551db6daea7ba99.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 125/150 /content/datasets/original-1/test/images/Re_367_jpg.rf.d2cae160cab50cf366b1532dcb79da3d.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 126/150 /content/datasets/original-1/test/images/Re_37_jpg.rf.2eb9ac92741596da72e01799b37420f0.jpg: 640x384 1 rejects, 22.4ms\n",
            "image 127/150 /content/datasets/original-1/test/images/Re_394_jpg.rf.35c944e7cf2a069960b62d616fe906a2.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 128/150 /content/datasets/original-1/test/images/Re_397_jpg.rf.241345393dc6433850dcf1264cdc38ed.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 129/150 /content/datasets/original-1/test/images/Re_399_jpg.rf.cea26b2cd9f9d943243640c299efba86.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 130/150 /content/datasets/original-1/test/images/Re_39_jpg.rf.b3e5d545ea3cc90f4bef0c04372c38e0.jpg: 640x384 1 rejects, 22.4ms\n",
            "image 131/150 /content/datasets/original-1/test/images/Re_410_jpg.rf.a374aff2950cba0bd64b6795d3993cb1.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 132/150 /content/datasets/original-1/test/images/Re_411_jpg.rf.581fbceba00403db7386f0309744fccc.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 133/150 /content/datasets/original-1/test/images/Re_414_jpg.rf.8ca8fa85f43ce2833e31224a67f2c3f8.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 134/150 /content/datasets/original-1/test/images/Re_415_jpg.rf.b068f88050a1977556bd991f9298e112.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 135/150 /content/datasets/original-1/test/images/Re_418_jpg.rf.2256a160aaba23f2111dfba23f1cfdc1.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 136/150 /content/datasets/original-1/test/images/Re_420_jpg.rf.87f97447634674e002fb7c07c399eb59.jpg: 640x480 1 rejects, 26.7ms\n",
            "image 137/150 /content/datasets/original-1/test/images/Re_431_jpg.rf.6f5d1dd57e58d1872351046dd323a2a0.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 138/150 /content/datasets/original-1/test/images/Re_471_jpg.rf.37ee2700fbae9a3d33d1718d0e57683b.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 139/150 /content/datasets/original-1/test/images/Re_477_jpg.rf.982201a28f5de257f46165d063ea357f.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 140/150 /content/datasets/original-1/test/images/Re_483_jpg.rf.228a259092dab8fe628e855acfca645e.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 141/150 /content/datasets/original-1/test/images/Re_487_jpg.rf.48b8f7599d960f7bb8c101bf2494f27c.jpg: 640x480 1 rejects, 27.0ms\n",
            "image 142/150 /content/datasets/original-1/test/images/Re_48_jpg.rf.ae0a2b1eae8a597d63cbefbf49549e06.jpg: 640x384 1 rejects, 22.4ms\n",
            "image 143/150 /content/datasets/original-1/test/images/Re_494_jpg.rf.1927de8fc487f5883d3f6fae31c58e69.jpg: 640x480 1 rejects, 26.8ms\n",
            "image 144/150 /content/datasets/original-1/test/images/Re_52_jpg.rf.b1b562df678e5d305eedc500c5d9e454.jpg: 640x384 1 rejects, 22.4ms\n",
            "image 145/150 /content/datasets/original-1/test/images/Re_61_jpg.rf.f4df616d009a03a21f76e493ff876cce.jpg: 640x384 1 rejects, 22.3ms\n",
            "image 146/150 /content/datasets/original-1/test/images/Re_66_jpg.rf.8bb23edca0a8bd2f733d317fa3cbc708.jpg: 640x384 1 rejects, 22.3ms\n",
            "image 147/150 /content/datasets/original-1/test/images/Re_67_jpg.rf.20162f5bce7deef5d53e5ad15c3698bf.jpg: 640x384 1 rejects, 22.3ms\n",
            "image 148/150 /content/datasets/original-1/test/images/Re_70_jpg.rf.3a146a631c095bc2ce0becbe3e5e6651.jpg: 640x384 1 accepts, 1 rejects, 22.3ms\n",
            "image 149/150 /content/datasets/original-1/test/images/Re_72_jpg.rf.cc3e5396576092246a12114483b607af.jpg: 640x384 1 rejects, 22.3ms\n",
            "image 150/150 /content/datasets/original-1/test/images/Re_77_jpg.rf.613eb90a6d90638ca2a61c7e22e7f963.jpg: 640x384 1 rejects, 22.3ms\n",
            "Speed: 0.5ms pre-process, 24.6ms inference, 2.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp7\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import cv2\n",
        "!python detect.py --weights '' --data ''--img 640 --conf 0.5 --source /content/datasets/original-1/test/images"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}